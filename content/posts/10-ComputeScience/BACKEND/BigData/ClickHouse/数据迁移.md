---
scope: learn
draft: true
---
## 迁移数据

[记一次 ClickHouse 数据迁移 - 知乎](https://zhuanlan.zhihu.com/p/220172155)

记录一下 ClickHouse 迁移数据的几种方法。网络上总结的一般有四种方法：

- 拷贝数据目录。需要对ClickHouse数据目录有一定了解，风险比较大，但是熟悉之后比较方便。
- remote 表函数。需要提前建表才能 SELECT INTO，手工操作比较多。
- ClickHouse-copier。官方比较推荐，安装了ClickHouse的机器上都有这个程序，功能也很强大。
- ClickHouse-backup。社区贡献的工具，可以像MySQL的mysqldump一样工作，需要下载且仅支持MergeTree系列的表。

### 拷贝数据目录

使用这种方法需要先了解一下 ClickHouse 数据目录的结构。例如 `/var/lib/clickhouse-server/`，需要关注的是 `data`、`metadata`、`store` 这三个文件夹。

可以使用 tree 命令查看一下目录结构：

```bash
tree -L 3 data metadata
data
├── dataflow
│   ├── car_sales_transactions -> /var/lib/clickhouse/store/7bb/7bb8b615-3756-4941-bbb8-b61537569941/
│   └── promotion_leases_transactions -> /var/lib/clickhouse/store/ad6/ad673427-ff04-4512-ad67-3427ff041512/
├── default
│   ├── 016c651c%2D75a5%2D4cf2%2D80e0%2D16d31bc2647d -> /var/lib/clickhouse/store/b36/b36c6a0d-7a51-427a-b36c-6a0d7a51927a/
│   ├── 0557354f%2De2ec%2D4e5e%2Dbb0d%2D06704c959156 -> /var/lib/clickhouse/store/54e/54eda3ba-075d-40e9-94ed-a3ba075dc0e9/
......
metadata
├── default -> /var/lib/clickhouse/store/86a/86ac973e-36e2-443c-86ac-973e36e2643c/
├── default.sql
├── system -> /var/lib/clickhouse/store/379/3798dce3-3258-4497-b798-dce33258d497/
├── system.sql
├── test -> /var/lib/clickhouse/store/01b/01b73247-ad9f-4a59-81b7-3247ad9f1a59/
└── test.sql
......
```

- `data` 目录是按照 `<database>/<table>` 组织的，通过软连接指向 `store` 目录，保存表数据。
- `metadata` 目录也是同样的结构，只是数据库的目录下面以同名的 `.sql` 文件保存了建库和建表的 DDL 语句，建表的 `.sql` 文件放在软连接指向的 `store` 目录下。



这样一来在迁移数据是就只需要拷贝这两个目录，复制完以后重启一下目标机器的ClickHouse服务端就可以了。但是要小心处理软连接，一旦数据目录下错误的链接和正常数据文件混杂就比较难解决了。

操作流程如下：

1. 在源集群的硬盘上打包好对应数据库或表的 data 和 metadata 数据
2. 拷贝到目标集群对应的数据目录
3. 重启 clickhouse-server

尝试过的一种方式是 tar 命令，其他的 cp 等命令应该也有相应的功能。把 data和metadata 目录打包到 clickhoue_data.tgz（使用 gzip方式压缩），同时通过 -h 参数跟踪软连接。

```bash
cd /var/lib/clickhouse-server
tar -zcpvhf /root/clickhouse_data.tgz data metadata
```





### remote 表函数

ClickHouse 除了查询常规的表，还能使用表函数来构建一些特殊的「表」，其中 [remote 函数](https://link.zhihu.com/?target=https%3A//clickhouse.tech/docs/en/sql-reference/table-functions/remote/) 可用于查询另一个 ClickHouse 的表。

使用方式很简单:

```sql
SELECT * FROM remote('addresses_expr', db, table, 'user', 'password') LIMIT 10;
```

因此，可以借助这个功能实现数据迁移：

```sql
INSERT INTO <local_database>.<local_table>
SELECT * FROM remote('remote_clickhouse_addr', <remote_database>, <remote_table>, '<remote_user>', '<remote_password>')
```

使用 `remote` 函数还能实现更多特性：

- 对于分区表，可逐个分区进行同步，这样实际上同步的最小单位是分区，可以实现增量同步
- 可方便集成数据完整性（行数对比）检查，自动重新同步更新过的表

操作流程

1. 在源集群的 `system.tables` 表查询出数据库、表、DDL、分区、表引擎等信息
2. 在目标集群上，运行 DDL 创建表，然后运行上述迁移语句复制数据
3. 遍历所有表，执行 2



### ClickHouse copier

- [Clickhouse-copier in practice – Altinity | The Real Time Data Company](https://altinity.com/blog/2018/8/22/clickhouse-copier-in-practice)
- [clickhouse-copier | ClickHouse Docs](https://clickhouse.com/docs/en/operations/utilities/clickhouse-copier/): https://clickhouse.com/docs/en/operations/utilities/clickhouse-copier/

是 ClickHouse 官方提供的一款数据迁移工具，可用于把表从一个集群迁移到另一个（也可以是同一个）集群。Clickhouse-copier 使用 Zookeeper 来管理同步任务，可以同时运行多个 clickhouse-copier 实例。

使用方式:

```bash
clickhouse-copier --daemon --config zookeeper.xml --task-path /task/path --base-dir /path/to/dir
```

其中 `--config zookeeper.xml` 是 Zookeeper 的连接信息，`--task-path /task/path` 是 Zookeeper 里任务配置的节点路径。在使用时，需要先定义一个 XML 格式的任务配置文件，上传到 `/task/path/description` 里。同步任务是表级别的，可以配置的内容还比较多。Clickhouse-copier 可以监听 `/task/path/description` 的变化，动态加载新的配置而不需要重启。

操作流程

1. 创建 `zookeeper.xml`
2. 创建任务配置文件，格式见官方文档，每个表都要配置（可使用代码自动生成）
3. 把配置文件内容上传到 Zookeeper
4. 启动 clickhouse-copier 进程

理论上 clickhouse-copier 运行在源集群或目标集群的环境都可以，官方文档推进在源集群，这样可以节省带宽。

### ClickHouse backup

[clickhouse-backup](https://link.zhihu.com/?target=https%3A//github.com/AlexAkulov/clickhouse-backup) 是社区开源的一个 ClickHouse 备份工具，可用于实现数据迁移。其原理是先创建一个备份，然后从备份导入数据，类似 MySQL 的 mysqldump + SOURCE。这个工具可以作为常规的异地冷备方案，不过有个局限是只支持 MergeTree 系列的表。

操作流程

1. 在源集群使用 `clickhouse-backup create` 创建备份
2. 把备份文件压缩拷贝到目标集群
3. 在目标集群使用 `clickhouse-backup restore` 恢复
